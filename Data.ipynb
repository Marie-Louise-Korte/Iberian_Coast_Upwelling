{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9995496-b6fb-4eba-9afe-9ff577a82a54",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing the Data\n",
    "\n",
    "## ERA5 (Ekman Upwelling Index)\n",
    "I am working with the mean turbulent surface stress $\\big[\\frac{N}{m^2}\\big]$ or [Pa] in eastward and northward direction, available from the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview). I download the data with the Copernicus tool that resamples it from hourly to daily resolution. [Download Link](https://cds.climate.copernicus.eu/apps/user-apps/app-c3s-daily-era5-statistics?dataset=reanalysis-era5-single-levels&product_type=reanalysis&variable_e5sl=eastward_turbulent_surface_stress&pressure_level_e5sl=-&statistic=daily_mean&year_e5sl=2020&month=01&frequency=1-hourly&time_zone=UTC%2B00:00&grid_e5=0.25/0.25&area.lat:record:list:float=36&area.lat:record:list:float=45&area.lon:record:list:float=-20&area.lon:record:list:float=-5).\n",
    "- Period: 01/12/1981-31/01/2024 (daily)\n",
    "- Resolution: 0.25° x 0.25°\n",
    "\n",
    "#### Processing\n",
    "1. Download data with Download_ERA5.py and specify variable, folder path and variable name for saving data\n",
    "    - conda activate IbUpPy3.9.12\n",
    "    - python3 Download_ERA5.py\n",
    "2. Download ERA5 land sea mask (and adapt) with Download_ERA5_land_sea_mask.ipynb\n",
    "2. Load the MTSS data\n",
    "    - after the download the data are all stored in individual files, I have one northward and eastward file per year\n",
    "    - load and combine the datasets\n",
    "    - save as MTSS.nc\n",
    "3. Load the SLP data\n",
    "4. Add land mask to MTSS & SLP\n",
    "5. Resample the data (MTSS & SLP)\n",
    "    - the data has daily resolution resample to weekly resolution (match the format of UI SST data as it already is at weekly resolution)\n",
    "    - wanted format: weekly mean Sat-Fr & time stamp Tue\n",
    "    - save the resampled data as MTSS_weekly.nc\n",
    "    - also calculate std and save as MTSS_weekly_std.nc\n",
    "6. (From MTSS calculate Ekaman transport -› when needed)\n",
    "    - calculate Ekman transport from the wind stress data\n",
    "    - calculate the Ekman upwelling index (aka the westward component of the Ekman transport)\n",
    "    - (save as UI_Ek.nc -› don't)\n",
    "\n",
    "## SST Upwelling Index\n",
    "I downloaded the data from [CoastNET geoportal](http://geoportal.coastnet.pt). This product is calculated with SST data obtained from [CORTAD](ahttps://www.ncei.noaa.gov/products/coral-reef-temperature-anomaly-database)\n",
    "- Period: 04/01/1982 - 09/11/2021 (weekly)\n",
    "- Resolution: lat: ~0.04166° and lon: 5.019 - 0.04166° (lon res does not really matter because this index calculates the difference between the temperature on the mid-shelf and at 15°W)\n",
    "\n",
    "#### Processing\n",
    "1. Download the data and save as UI_SST_CoastNET.nc\n",
    "2. Load the data\n",
    "3. Convert the temperature from Kelvin to °C for more intuitive understanding\n",
    "4. Change the sign of the index\n",
    "    - the index is calculated by substracting the midshelf temperatures from the 15°W temperatures ($T_{mid-shelf} \\ - \\ T_{15^{\\circ}W} \\ = \\ UI_{SST}$)\n",
    "    - multiply by -1 so that positive values indicate upwelling\n",
    "    - save as UI_SST.nc\n",
    "\n",
    "## ECCO2 SST & SSH\n",
    "Download the [ECCO2 data](https://ecco.jpl.nasa.gov/drive/files/ECCO2/cube92_latlon_quart_90S90N/)\n",
    "- Period 01/01/1992 - 31/12/2023\n",
    "- Resolution: 0.25°\n",
    "\n",
    "1. Download the data with Download_ECCO2.txt\n",
    "    - Download_ECCO2.txt is and executable file\n",
    "    - execute the file in the terminal by just running its name ./Download_ECCO2.txt\n",
    "3. Load the data\n",
    "4. Select research area (35°N to 45°N, 20°W (340°E) to 5°W (355°E))\n",
    "5. Resample the data\n",
    "    - the data has daily resolution resample to weekly resolution (match the format of UI SST data as it already is at weekly resolution)\n",
    "    - wanted format: weekly mean Sat-Fr & time stamp Tue\n",
    "    - save the resampled data as ECCO2_weekly.nc\n",
    "    - (also calculate std and save as ECCO2_weekly_std.nc)\n",
    "      \n",
    "## IBI SSH\n",
    "Downloaded the data for the Iberian Peninsula from [Copernicus Marine Serivce](https://data.marine.copernicus.eu/product/IBI_MULTIYEAR_PHY_005_002/description)\n",
    "- Period 01/01/1993 - 28/12/2021\n",
    "- Resolution: 0.083° x 0.083°\n",
    "\n",
    "#### Processing\n",
    "1. Download the data with Download_SSH.ipynb\n",
    "    - rename latitude, lat and longitude, lon\n",
    "2. Load the data\n",
    "3. Rename lat, lon, time\n",
    "4. Cut research area from global dataset\n",
    "5. Resample the data\n",
    "    - the data has daily resolution resample to weekly resolution (match the format of UI SST data as it already is at weekly resolution)\n",
    "    - wanted format: weekly mean Sat-Fr & time stamp Tue\n",
    "    - save the resampled data as SSH_weekly.nc\n",
    "    - (also calculate std and save as SSH_weekly_std.nc)\n",
    "  \n",
    "## CoRTAD SST\n",
    "Download data from [NOAA](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.nodc:NCEI-CoRTADv6)\n",
    "- Period 01/05/1982 - 27/12/2022\n",
    "- Resolution: 0.04165649° x 0.04165649°\n",
    "\n",
    "#### Processing\n",
    "1. Download the cortadv6_FilledSST.nc via the link on the HTTPS download on the NOAA website and save as CoRTAD_global.nc\n",
    "2. Drop the dimension 'nv'\n",
    "3. Select research area (35°N to 45°N, 20°W (340°E) to 5°W (355°E))\n",
    "4. Is the dataset to which we are all matching our weekly resampling (so don't need to do anything)\n",
    "5. Change °K to °C\n",
    "    - Save as CoRTAD_weekly.nc\n",
    "  \n",
    "## Extended ERA5 \n",
    "MTSS and SST from ERA5 Copernicus\n",
    "\n",
    "#### Processing\n",
    "As specified for ERA5 above.\n",
    "\n",
    "## NAO\n",
    "Download Data from [NOAA](https://ftp.cpc.ncep.noaa.gov/cwlinks/norm.daily.nao.cdas.z500.19500101_current.csv)\n",
    "- period 01/01/1950 - present\n",
    "\n",
    "#### Processing\n",
    "1. Download the data file norm.daily.nao.cdas.z500.19500101_current.csv on the NOAA NAO website and save as NAO.csv\n",
    "2. Get a date variable\n",
    "3. Combine date and data into an xarray\n",
    "4. Resample the data\n",
    "    - the data has daily resolution resample to weekly resolution (match the format of UI SST data as it already is at weekly resolution)\n",
    "    - wanted format: weekly mean Sat-Fr & time stamp Tue\n",
    "    - save the resampled data as NAO_weekly.nc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f1b831-f253-4575-a861-082821adb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import my_functions\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore') # ignore runtime warning for SSH.resample(...).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35a0a10-66d3-4d43-8f21-d260916e462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set directory to where datasets are stored\n",
    "os.chdir(\"/Users/marie-louisekorte/Documents/Uni Leipzig/Lisbon/Data.nosync/\")\n",
    "#os.chdir(\"/Volumes/Jamie/\")\n",
    "#os.chdir(\"/Users/marie-louisekorte/Documents/Uni Leipzig/Lisbon/Data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5f5ae-7771-4b0b-ac1c-1e91745372a1",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000d513-28ae-4dc9-8263-3e07bd3b20ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9532cdd-0229-4d6c-9dc7-3379e27e9209",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ERA5 mean turbulent surface stress\n",
    "# load data in chunks to avoid jupyter lab crashing\n",
    "MTSS_19th = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/Surface_stress/Turbulent_mean/*_19*.nc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330df4fb-3788-46c5-88f1-bc32346b44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MTSS_20th_N = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/Surface_stress/Turbulent_mean/N_20*.nc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79bde7-8165-4934-82d9-d90165ea5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "MTSS_20th_E = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/Surface_stress/Turbulent_mean/E_20*.nc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f6018-6617-4812-aeb7-9e1b2aa80132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets  (and drop empty coordinate \"realization\")\n",
    "MTSS = xr.merge([MTSS_19th, MTSS_20th_N, MTSS_20th_E])\n",
    "MTSS = MTSS.drop_vars([\"realization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29f02e-37d7-4914-8e9a-a25970b860b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as netcdf \n",
    "MTSS.to_netcdf(\"MTSS.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2729e7f-817b-434f-99fd-e4a573c41977",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ERA5 land sea mask\n",
    "LSM = xr.open_dataset(\"Land_sea_mask.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de1b4584-a27a-49dd-8a41-7d34a5a70e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load SLP\n",
    "SLP_19th = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/SLP/*_19*.nc')])\n",
    "SLP_20th = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/SLP/*_20*.nc')])\n",
    "SLP = xr.merge([SLP_19th, SLP_20th])\n",
    "SLP = SLP.drop_vars([\"realization\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2815617-207d-44ab-b235-71793f92a3c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### UI SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af566f8-8563-4ad0-b0c9-7c7482505851",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load UI SST\n",
    "UI_SST = xr.open_dataset('UI_SST_CoastNET.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6740bc-3e9e-4461-946f-e8b5f2c579a8",
   "metadata": {},
   "source": [
    "### ECCO2 SST & SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "540cbac9-72fb-4052-9eb2-30fce73cced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ECCO2 SST\n",
    "for year in np.arange(1992, 2024):\n",
    "    for month in np.arange(1, 13):\n",
    "        ds = xr.open_dataset(f'ECCO2/ECCO2_SST/SST.1440x720.{year}{month:02d}.nc')\n",
    "        ds = ds.sel(LATITUDE_T = slice(35, 45), LONGITUDE_T = slice(340, 355))\n",
    "        if ((year == 1992) and (month == 1)):\n",
    "            ECCO2_SST = ds\n",
    "        ECCO2_SST = xr.merge([ECCO2_SST, ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6174f53-2e8d-4679-ae70-f6a1c5139a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ECCO2 SSH\n",
    "for year in np.arange(2020, 2024):\n",
    "    for month in np.arange(1, 13):\n",
    "        ds = xr.open_dataset(f'ECCO2/ECCO2_SSH/SSH.1440x720.{year}{month:02d}.nc')\n",
    "        ds = ds.sel(LATITUDE_T = slice(35, 45), LONGITUDE_T = slice(340, 355))\n",
    "        if ((year == 1992) and (month == 1)):\n",
    "            ECCO2_SSH = ds\n",
    "        ECCO2_SSH = xr.merge([ECCO2_SSH, ds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7c315-1127-422d-8526-4e6bd366f24f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### IBI SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83c0e76c-2908-4a20-92b2-95cd7bd42537",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load SSH\n",
    "SSH = xr.open_dataset('SSH_daily.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e77f4b-e40f-405c-8f52-0cb5ba120abc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CoRTAD SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8f29a0-a9d9-49bd-806d-f54c5b1546c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load SST\n",
    "SST = xr.open_dataset('cortadv6_FilledSST.nc')\n",
    "SST = SST.drop_dims([\"nv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613f824-81ca-4dcb-bdfa-71c972073685",
   "metadata": {},
   "source": [
    "### NAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96eb9581-2880-4c97-a626-c4ad11aa677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nao = np.genfromtxt('NAO.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234cff84-f44e-4b3d-8bf6-46a159036df6",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "81a21399-40a4-495c-8acd-f57d9bdbdcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wd to where I want the datasets to be saved\n",
    "os.chdir(\"/Users/marie-louisekorte/Documents/Uni Leipzig/Lisbon/Data.nosync/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc82f1a-19d1-499b-ac74-5f6990a0c801",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32444386-e252-4893-aeb9-549585550601",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process ERA5 - weekly resmaple\n",
    "# resample ERA5 data to same weekly resolution as SST upwelling index (Weekly mean Sat-Fr & time stamp Tue)\n",
    "# time = 'W-SAT' -> resamples to weekly time res. starting on a Saturday (default is Sunday)\n",
    "# closed = 'left' -> means [start date, end_date) i.e. start date is included and end_date is exluded in the interval I choose \n",
    "# label = 'left' -> the time stamp from the start of the interval is assigned\n",
    "MTSS_weekly_mean = MTSS.resample(time = 'W-SAT', closed = 'left', label = 'left').mean() \n",
    "# change time label ->I want to add 3 days to my time coordinate to move my time stamp from Sat to Tue to match SST upwelling index format\n",
    "MTSS_weekly_mean['time'] = MTSS_weekly_mean.time + np.timedelta64(3, 'D')\n",
    "\n",
    "# add land-sea mask to the MTSS dataset\n",
    "MTSS_weekly_mean['lsm'] = LSM.lsm\n",
    "\n",
    "# save as netcd\n",
    "MTSS_weekly_mean.to_netcdf(\"MTSS_weekly.nc\")\n",
    "\n",
    "# same for std\n",
    "#MTSS_weekly_std =  MTSS.resample(time = 'W-SAT', closed = 'left', label = 'left').std() \n",
    "#MTSS_weekly_std['time'] = MTSS_weekly_std.time + np.timedelta64(3, 'D')\n",
    "#MTSS_weekly_std['lsm'] = LSM.lsm\n",
    "#MTSS_weekly_std.to_netcdf(\"MTSS_weekly_std.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d87cd72-80c3-4e0a-b232-4bb11b474a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process ERA5 - calculate Ekman upwelling index\n",
    "# calculate upwelling index from wind stress dataset -> use my upwelling function (from my_functions.py)\n",
    "# UI_Ek = my_functions.calc_upwelling_index(MTSS, MTSS.lat, MTSS.lon, MTSS.metss, MTSS.mntss)\n",
    "\n",
    "# save as netcdf\n",
    "# UI_Ek.to_netcdf(\"UI_Ek.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b2830e8-acc0-4976-b9a8-54f0f6c139ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process ERA5 - SLP - weekly resample\n",
    "## process SSH -> resample to weeky res\n",
    "SLP_weekly_mean = SLP.resample(time = 'W-SAT', closed = 'left', label = 'left').mean() \n",
    "SLP_weekly_mean['time'] = SLP_weekly_mean.time + np.timedelta64(3, 'D')\n",
    "\n",
    "# add land-sea mask \n",
    "SLP_weekly_mean['lsm'] = LSM.lsm\n",
    "# save as netcd\n",
    "SLP_weekly_mean.to_netcdf(\"SLP_weekly.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d66f60-dd67-40d5-ac62-b41af0ddb722",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SST UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f9c97d-78f3-4bc0-9782-98d5a4f3e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process SST UI - convert Kelvin to °C\n",
    "# also upedate the attributes\n",
    "UI_SST['Tmid'] = UI_SST.Tmid - 273.15\n",
    "UI_SST.Tmid.attrs.update({\"name\" : \"sea_surface_skin_temperature\", \"units\" : \"degree Celsius °C\"})\n",
    "UI_SST['Toff15W'] = UI_SST.Toff15W - 273.15\n",
    "UI_SST.Toff15W.attrs.update({\"name\" : \"sea_surface_skin_temperature\", \"units\" : \"degree Celsius °C\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57e5348-f3d2-44d4-ba05-60ae97830f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process SST UI - change sign of index\n",
    "UI_SST['UI'] = UI_SST.UI * -1\n",
    "UI_SST.UI.attrs.update({\"name\" : \"difference in sea_surface_skin_temperature\", \"units\" : \" degree Celsius °C\", \"method\" : \" Toff15 - Tmid\", \"info\" : \" > 2°C upwelling event\"})\n",
    "\n",
    "# save as netcdf\n",
    "UI_SST.to_netcdf(\"UI_SST.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4f40b-a5ba-43ac-bceb-e673020f3959",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ECCO2 SST & SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a69aac50-75a1-449f-81e2-a97b665b80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process rename lat, lon and time\n",
    "ECCO2 = xr.merge([ECCO2_SST, ECCO2_SSH])\n",
    "ECCO2 = ECCO2.rename({'LATITUDE_T' : 'lat', 'LONGITUDE_T' : 'lon', 'TIME' : 'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bf5b532-2570-4ce1-9d6f-71a683943149",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process ECCO2 SST -> resample to weeky res\n",
    "ECCO2_weekly_mean = ECCO2.resample(time = 'W-SAT', closed = 'left', label = 'left').mean() \n",
    "ECCO2_weekly_mean['time'] = ECCO2_weekly_mean.time + np.timedelta64(3, 'D')\n",
    "\n",
    "# save as netcd\n",
    "ECCO2_weekly_mean.to_netcdf(\"ECCO2_weekly.nc\")\n",
    "\n",
    "## same for std\n",
    "#ECCO2_weekly_std =  ECCO2.resample(time = 'W-SAT', closed = 'left', label = 'left').std() \n",
    "#ECCO2_weekly_std['time'] = ECCO2_weekly_std.time + np.timedelta64(3, 'D')\n",
    "#ECCO2_weekly_std.to_netcdf(\"SSH_weekly_std.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6de53c-e645-4f9b-acfd-d3788cd3830f",
   "metadata": {},
   "source": [
    "### IBI SSH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "06869e58-cd4b-42bc-b94f-003f5bf7a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process SSH -> resample to weeky res\n",
    "SSH_weekly_mean = SSH.resample(time = 'W-SAT', closed = 'left', label = 'left').mean() \n",
    "SSH_weekly_mean['time'] = SSH_weekly_mean.time + np.timedelta64(3, 'D')\n",
    "\n",
    "# drop first date (assigns a day from 1992 which get confusing later on)\n",
    "SSH_weekly_mean = SSH_weekly_mean.sel(time = slice('01-01-1993', None))\n",
    "\n",
    "# save as netcd\n",
    "SSH_weekly_mean.to_netcdf(\"SSH_weekly.nc\")\n",
    "\n",
    "## same for std\n",
    "#SSH_weekly_std =  SSH.resample(time = 'W-SAT', closed = 'left', label = 'left').std() \n",
    "#SSH_weekly_std['time'] = SSH_weekly_std.time + np.timedelta64(3, 'D')\n",
    "#SSH_weekly_std.to_netcdf(\"SSH_weekly_std.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796a10e-8104-4d29-87a0-cc8ed3be4bdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CoRTAD SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca64a44-7ac3-4b7a-9e86-45e061c17c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process CoRTAD SST \n",
    "# reverse order of lat\n",
    "SST = SST.reindex(lat=list(reversed(SST.lat)))\n",
    "\n",
    "# select research area\n",
    "SST = SST.sel(lat = slice(45, 35), lon = slice(-20, -5))\n",
    "\n",
    "SST['SST'] = SST.FilledSST - 273.15\n",
    "SST.SST.attrs.update({\"standard_name\" : \"sea_surface_skin_temperature\", \"units\" : \" degree Celsius °C\", \"info\" : \"WeeklySST - 273.15\"})\n",
    "\n",
    "# save as netcdf\n",
    "SST.to_netcdf(\"CoRTAD_weekly.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f877c-c87d-4280-8dad-1f68862e0187",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Extended ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2db0f57-0225-4226-b2a6-d09cc9162286",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MTSS\n",
    "# load additional data\n",
    "os.chdir(\"/Users/marie-louisekorte/Documents/Uni Leipzig/Lisbon/Data/\")\n",
    "MTSS_1940s = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/MTSS/*_194*.nc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0605ede8-be65-4015-a963-d988ec5bc033",
   "metadata": {},
   "outputs": [],
   "source": [
    "MTSS_1950s = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/MTSS/*_195*.nc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "881a834f-920f-4548-a2f1-6a5f65da31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MTSS_1960s = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/MTSS/*_196*.nc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f12139e-8601-457d-b3ad-7bea14069c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "MTSS_1970s = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/MTSS/*_197*.nc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef6065d7-0e3d-4f0f-baab-61da9b6674c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MTSS_1980s = xr.merge([xr.open_dataset(f) for f in glob.glob('ERA5/MTSS/*_198*.nc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e804ddc4-79e3-474a-af41-739b7988e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/marie-louisekorte/Documents/Uni Leipzig/Lisbon/Data.nosync/\")\n",
    "MTSS = xr.open_dataset('MTSS.nc')\n",
    "MTSS_all = xr.merge([MTSS_1940s, MTSS_1950s, MTSS_1960s, MTSS_1970s, MTSS_1980s, MTSS])\n",
    "MTSS_all = MTSS_all.drop_vars([\"realization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08150ce1-3960-4669-8dde-164184291dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekly mean\n",
    "MTSS_all_weekly_mean = MTSS_all.resample(time = 'W-SAT', closed = 'left', label = 'left').mean() \n",
    "MTSS_all_weekly_mean['time'] = MTSS_all_weekly_mean.time + np.timedelta64(3, 'D')\n",
    "\n",
    "# add land-sea mask to the MTSS dataset\n",
    "MTSS_all_weekly_mean['lsm'] = LSM.lsm\n",
    "\n",
    "# save as netcd\n",
    "MTSS_all_weekly_mean.to_netcdf(\"MTSS_all_weekly.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "991903cd-157f-41a5-a3cc-435323383e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ERA5 SST\n",
    "# load ERA5_SST\n",
    "os.chdir(\"/Users/marie-louisekorte/Documents/Uni Leipzig/Lisbon/Data/\")\n",
    "for year in np.arange(2016, 2024):\n",
    "    for month in np.arange(1, 13):\n",
    "        ds = xr.open_dataset(f'ERA5/SST/SST_{year}_{month:02d}.nc')\n",
    "        if ((year == 1940) and (month == 1)):\n",
    "            ERA5_SST = ds\n",
    "        ERA5_SST = xr.merge([ERA5_SST, ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8375bd51-dcef-42f1-9c53-70b90f360175",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_SST = ERA5_SST.drop_vars([\"realization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55387dde-c9ad-4d83-a6e7-be68acc6e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekly mean\n",
    "ERA5_SST_weekly_mean = ERA5_SST.resample(time = 'W-SAT', closed = 'left', label = 'left').mean() \n",
    "ERA5_SST_weekly_mean['time'] = ERA5_SST_weekly_mean.time + np.timedelta64(3, 'D')\n",
    "\n",
    "# add land-sea mask to the MTSS dataset\n",
    "ERA5_SST_weekly_mean['lsm'] = LSM.lsm\n",
    "\n",
    "# get SST var in °C\n",
    "ERA5_SST_weekly_mean['SST'] = ERA5_SST_weekly_mean.sst - 273.15\n",
    "ERA5_SST_weekly_mean.SST.attrs.update({\"standard_name\" : \"sea_surface_skin_temperature\", \"units\" : \" degree Celsius °C\", \"info\" : \"WeeklySST - 273.15\"})\n",
    "\n",
    "# save as netcd\n",
    "os.chdir(\"/Users/marie-louisekorte/Documents/Uni Leipzig/Lisbon/Data.nosync/\")\n",
    "ERA5_SST_weekly_mean.to_netcdf(\"ERA5_SST_weekly.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d19415-f88c-432b-ba95-48c22106884b",
   "metadata": {},
   "source": [
    "### NAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "43789847-52ab-49df-85ea-a895fbea2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dates\n",
    "nao_dates = np.arange(np.datetime64(str(f'{nao[1,0]:.0f}-{round(nao[1,1]):02d}-{round(nao[1,2]):02d}')), (str(f'{nao[-1,0]:.0f}-{round(nao[-1,1]):02d}-{round(nao[-1,2]):02d}')))\n",
    "\n",
    "# create xarray\n",
    "NAO = xr.Dataset(\n",
    "    {\n",
    "        \"NAO\": (\n",
    "            (\"time\"),\n",
    "            nao[1:-1,3],\n",
    "        ),\n",
    "    },\n",
    "    coords = dict(time = nao_dates,),\n",
    "    attrs = dict(\n",
    "        description = \"North Atlantic Oscillation\",\n",
    "        source = \"NOAA\",\n",
    "        url = \"https://ftp.cpc.ncep.noaa.gov/cwlinks/norm.daily.nao.cdas.z500.19500101_current.csv\",\n",
    "        info = \"standardized anomalies are calculated based on the 1950-2000 climatological daily mean\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "57bbc345-0c06-4820-adff-eadbaf13e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process NAO -> resample to weeky res\n",
    "NAO_weekly_mean = NAO.resample(time = 'W-SAT', closed = 'left', label = 'left').mean() \n",
    "NAO_weekly_mean['time'] = NAO_weekly_mean.time + np.timedelta64(3, 'D')\n",
    "\n",
    "# save as netcd\n",
    "NAO_weekly_mean.to_netcdf(\"NAO_weekly.nc\")\n",
    "\n",
    "## same for std\n",
    "#NAO_weekly_std =  NAO.resample(time = 'W-SAT', closed = 'left', label = 'left').std() \n",
    "#NAO_weekly_std['time'] = NAO_weekly_std.time + np.timedelta64(3, 'D')\n",
    "#NAO_weekly_std.to_netcdf(\"NAO_weekly_std.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IbUp Py3.9.12",
   "language": "python",
   "name": "ibuppy3.9.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
